{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619822c0-1bd5-444c-9aee-f26a60c3f9dd",
   "metadata": {},
   "source": [
    "## Shallow Shadows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6328a-95a2-4d8a-ae08-2ea3b8ad0841",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "For a given ensemble of random unitaries $\\{u\\}$, the measurement or shadow channel $\\mathcal{M}$ is defined as $\\rho \\rightarrow \\mathcal{M}(\\rho)=\\mathbb{E}_u \\left[  \\sum_s \\bra{s}u\\rho u^\\dagger \\ket{s}u^\\dagger \\ket{s}\\bra{s}u\\right]$ where $\\mathbb{E}_u$ denotes the average over the random unitary ensemble. For certain ensembles, in particular local (single-qubit) and global (N-qubit) unitaries from unitary 2-designs, the channel and its inverse $\\mathcal{M}^{-1}$ can be computed analytically (Huang et al., Nat. Phys. 2020). We can then use it to construct classical shadows for arbitrary input states $\\rho$: $\\hat{\\rho}=\\mathcal{M}^{-1}(u^\\dagger \\ket{s}\\bra{s}u)$ where $s$ is the outcome bitstring  of a single computational basis measurement performed on $u\\rho u^\\dagger$.\n",
    "\n",
    "For more general ensembles of random unitaries, we need to learn the channel $\\mathcal{M}$, then invert it to form shadows and obtain a randomized measurement protocol.\n",
    "\n",
    "This notebook illustrates this for case of random unitaries formed by shallow random quantum circuits [Hu et al., PRR 5, 023027 (2023)](https://doi.org/10.1103/PhysRevResearch.5.023027), [Akhtar et al., Quantum 7, 1026 (2023)](https://quantum-journal.org/papers/q-2023-06-01-1026), [Bertoni et al, Phys. Rev. Lett. 133, 020602 (2024)](https://link.aps.org/doi/10.1103/PhysRevLett.133.020602) and [Hu et al.,Nat Commun 16, 2943 (2025)](https://doi.org/10.1038/s41467-025-57349-w). Importantly, we use the property that shallow random quantum circuits are locally scrambling circuits. This allows us to learn a representation of the channel from evaluating its action on single initial product state  [Hu et al., PRR 5, 023027 (2023)](https://doi.org/10.1103/PhysRevResearch.5.023027)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc9666",
   "metadata": {},
   "source": [
    "### Learning depolarization vectors\n",
    "In Ref. [Hu et al., PRR 5, 023027 (2023)](https://doi.org/10.1103/PhysRevResearch.5.023027), it has been shown that with locally scrambling unitaries \n",
    "$$\\mathcal{M}(\\rho)=\\sum_v c_v (\\rho_{A(v)}\\otimes 1_{B(v)}/2^{|B(v)|})$$\n",
    "where we sum over all $2^N$ bitstrings $v=(v_1,v_2,\\dots,v_N)$, and $A(v)=\\{i| v_i=0\\}$, and $B(v)=\\{i|v_i=1\\}$ denote the set of indices $i$ where $v_i$ is $0$ and $1$, respectively.\n",
    "Thus, the \"depolarization vector\" $\\vec{c} = (c_1,\\dots,c_{2^N})$ fully specifies the channel $\\mathcal{M}(\\cdot)$.\n",
    "\n",
    "Let us consider an initial state $\\rho_0=\\ket{0}\\bra{0}$. We have the equality \n",
    "$$c_v=\\mathrm{tr}(\\mathcal{M}(\\rho_0)O_v)$$\n",
    "with $O_v=\\bigotimes_{i}\\left((\\ket{0}\\bra{0}-\\ket{1}\\bra{1})\\delta_{v=1}+2(\\ket{1}\\bra{1})\\delta_{v=0}\\right)$. Therefore, the action of the channel $\\mathcal{M}(\\cdot)$ on the single initial state $\\rho_0=\\ket{0}\\bra{0}$ fully specifies the vector $c_v$ and, hence, the channel $\\mathcal{M}(\\cdot)$.\n",
    "\n",
    "To learn the vector $\\vec{c}$, first we recall that \n",
    "$$\\mathcal{M}(\\rho_0)=\\mathbb{E}_U\\left[\\sum_s \\braket{s|U\\rho_0U^\\dag|s} U^\\dag \\ket{s}\\bra{s} U \\right].$$\n",
    " \n",
    "Therefore, $c_v=\\mathbb{E}_U[c_v(U)]$, with \n",
    "$$c_v(U)=\\sum_s \\braket{s|U\\rho_0U^\\dag|s} \\braket{s|U O_v U^\\dag|s}.$$\n",
    "\n",
    "For a set of random unitaries $U$, these depolarization vectors $\\vec{c}(U)=(c_1(U), \\dots, c_{2^N}(U))$ can be computed as Matrix-Product-States (MPS) by evolving $\\rho_0$ and $O_v$, using ITensor's internal routine [apply](https://itensor.github.io/ITensors.jl/dev/tutorials/MPSTimeEvolution.html),  and contracting the physical indices $s$. For instance, with a random circuit of depth 2, this is done as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e4b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using RandomMeas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f92176d6-2580-4fec-afd8-f7ee27f000cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:38\u001b[39m\u001b[K\u001b[39m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "NU_training = 2000 # Number of unitaries\n",
    "N = 10\n",
    "ξ = siteinds(\"Qubit\", N;addtags=\"output\")\n",
    "depth = 2\n",
    "\n",
    "settings = [ShallowUnitaryMeasurementSetting(N,depth;site_indices=ξ) for _ in 1:NU_training]\n",
    "shallow_depolarization_mps = get_shallow_depolarization_mps(settings);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d8290",
   "metadata": {},
   "source": [
    "### Fitting the average depolarization vector as an MPS\n",
    "\n",
    "We now compute an matrix product state (MPS) approximation $\\vec{c}$ of the average depolarization vector $ 1/{N_u}\\sum_U c_v(U)$. To efficiently obtain such MPS approximation without actually computing the direct average $ 1/{N_u}\\sum_U c_v(U)$ as a dense vector, we adapt a fitting algorithm presented in [T Baumgratz et al 2013 New J. Phys. 15 125004](https://iopscience.iop.org/article/10.1088/1367-2630/15/12/125004): We minimize the cost function $\\vec{c}=\\argmin_{\\vec{x}}\\mathcal{C}(\\vec{x})$ with $$ \\mathcal{C}(\\vec{x}) =||\\vec{x}-1/N_U\\sum_U \\vec{c}(U)||^2_2-||1/N_U\\sum_U \\vec{c}(U)||^2_2.$$ We note that the second term is constant (does not depend on $\\vec{x}$) and has been added in order to facilitate the cost function evaluation (runtime $O(N_u)$ instead of $O(N_u^2)$). The compression algorithm updates each tensor sequentially over a finite number of sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e972eea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function 1.039459271943392\n",
      "Cost function -0.3347986119869886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:03\u001b[39m\u001b[K\n",
      "\u001b[32mProgress:  33%|█████████████▋                           |  ETA: 0:00:45\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function -0.3348031181519736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\u001b[K\n",
      "\u001b[32mProgress:  50%|████████████████████▌                    |  ETA: 0:00:27\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function -0.3348042698811304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:04\u001b[39m\u001b[K\n",
      "\u001b[32mProgress:  67%|███████████████████████████▍             |  ETA: 0:00:18\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function -0.3348046988020203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\u001b[K\n",
      "\u001b[32mProgress:  83%|██████████████████████████████████▏      |  ETA: 0:00:08\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function -0.33480497888854255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\u001b[K\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\u001b[K\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function -0.33480518360135286\n"
     ]
    }
   ],
   "source": [
    "nsweeps = 6 # Number of sweeps for the fitting \n",
    "χ = 4 # We minimize the cost function C in the space of MPS with the bond dimension χ.\n",
    "average_shallow_depolarization_mps = get_average_mps(shallow_depolarization_mps,χ,nsweeps);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e48f4",
   "metadata": {},
   "source": [
    "### Inverting the channel\n",
    "\n",
    "For local invariant unitaries, the inverse channel has the following form ([Hu et al., PRR 5, 023027 (2023)](https://doi.org/10.1103/PhysRevResearch.5.023027)):\n",
    "$$\\mathcal{M}^{-1}(\\sigma)=\\sum_v d_v (\\sigma_{A(v)}\\otimes 1_{B(v)}/{2^{|B(v)|}})$$\n",
    "with $\\vec{d} = (d_1,\\dots,d_{2^N})$.\n",
    "\n",
    "Thus, we want to find a vector $\\vec{d}$ such that, for all $\\rho$, \n",
    "$$[\\mathcal{M}^{-1}\\circ\\mathcal{M}](\\rho)=\\rho$$\n",
    "\n",
    "\n",
    "This can be satisfied by minimizing the cost function\n",
    "\n",
    "$$\\mathcal{C}'(\\vec{x})=||\\mathcal{M}^{-1}\\circ\\mathcal{M}-1||_2^2$$\n",
    "\n",
    "such that $\\vec{d} = \\argmin_{\\vec{x}} \\mathcal{C}'(\\vec{x})$.\n",
    "\n",
    "To do this efficiently, we parametrize $\\vec{x}$ as an MPS with finite bond dimension $\\chi$ and write $\\mathcal{C}'(\\vec{x})$ as a result of a tensor contraction, whose gradients with respects to the tensors of the MPS $\\vec{x}$ can be evaluated by automatic differentations using the package Zygote. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62f204ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss 0.999835746019643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: LBFGS: not converged to requested tol after 100 iterations and time 129.29 s: f = 0.001108899767, ‖∇f‖ = 7.1176e-03\n",
      "└ @ OptimKit /home/vermersch/.julia/packages/OptimKit/G6i79/src/lbfgs.jl:197\n"
     ]
    }
   ],
   "source": [
    "using OptimKit\n",
    "s = siteinds(\"Qubit\", N;addtags=\"input\")\n",
    "shallow_map = get_depolarization_map(average_shallow_depolarization_mps,s,ξ)\n",
    "v = siteinds(\"Qubit\", N)  # Virtual Site indices\n",
    "inverse_depolarization_mps_data_init = randomMPS(Float64,v;linkdims=χ).data\n",
    "\n",
    "#evaluates the loss function defined above\n",
    "loss(x) = loss_inverse_depolarization_map(x,shallow_map,v,s,ξ)\n",
    "println(\"initial loss \",loss(inverse_depolarization_mps_data_init))\n",
    "\n",
    "#optimize!\n",
    "optimizer = LBFGS(; maxiter=100, verbosity=1, gradtol = 1e-4)\n",
    "loss_and_grad(x) = loss(x),loss'(x)\n",
    "inverse_depolarization_mps_data, fs, gs, niter, normgradhistory = optimize(loss_and_grad, inverse_depolarization_mps_data_init, optimizer)\n",
    "inverse_depolarization_mps = MPS(inverse_depolarization_mps_data)\n",
    "inverse_shallow_map = get_depolarization_map(inverse_depolarization_mps,s,ξ);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613daa8-d647-44f4-8c2d-d0df42833c97",
   "metadata": {},
   "source": [
    "## Simulated experiment\n",
    "We are ready to perform an experiment on a unknown state $\\ket{\\psi}$, build shadows as MPO and estimate expectation values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32a754",
   "metadata": {},
   "source": [
    "We aim to estimate XX correlations. We construct the corresponding MPOs and compute the exact expectation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0118d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "ψ = random_mps(ξ; linkdims=χ);\n",
    "\n",
    "observable = Vector{MPO}()\n",
    "for i in 1:N-1\n",
    "    ampo = AutoMPO()\n",
    "    ampo .+= \"X\", i,\"X\",i+1\n",
    "    push!(observable,MPO(ampo,ξ))\n",
    "end\n",
    "\n",
    "observable_exact = Vector{Float64}()\n",
    "for o in observable\n",
    "    push!(observable_exact,real(inner(ψ',o,ψ)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4656e",
   "metadata": {},
   "source": [
    "For a given unitary, we know that the correspond shadow estimator for an observable $O$ can be written as \n",
    "$$O_e = \\sum_s P_U(s) \\mathrm{tr}(\\mathcal{M}^{-1}(U^\\dag\\ket{s}\\bra{s}U) O)=\\sum_s P_U(s) \\braket{s|U\\mathcal{M}^{-1}(O)U^\\dag|s}$$\n",
    "where $P_U(s)$ is the estimated Born probability, and we have used the fact that $\\mathcal{M}^{-1}$ is self-adjoint.\n",
    "\n",
    "The expression given in the last term allows us to apply lest costly operations compared to the second term, but requires to form the probability vector $P_U(s)$ of dimension $2^N$. Let us check these two ways of estimating an observable for a single unitary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb7c4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NU = 100\n",
    "NM = 500\n",
    "measurement_group_dense = MeasurementGroup(ψ,NU,NM,depth;mode=\"dense\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7a28e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40.088229 seconds (42.58 M allocations: 6.486 GiB, 8.28% gc time, 66.76% compilation time)\n",
      "first method 0.4309070401227886\n",
      " 35.218691 seconds (25.77 M allocations: 1.282 GiB, 1.58% gc time, 99.85% compilation time)\n",
      "second method 0.4309070401227865\n"
     ]
    }
   ],
   "source": [
    "r = 1 #First measurement setting\n",
    "j = 1\n",
    "measurement_data = measurement_group_dense.measurements[r]\n",
    "##First method (slow, memoryefficient)\n",
    "@time begin\n",
    "    shadow_r = get_shallow_shadows(measurement_data,inverse_shallow_map,s,ξ)\n",
    "    estimation_1 = real(get_expect_shadow(observable[j],shadow_r))\n",
    "end\n",
    "println(\"first method \", estimation_1)\n",
    "\n",
    "\n",
    "##Second method (fast, memory ~2^N)\n",
    "@time estimation_2 = real(get_expect_shadow(observable[j],measurement_data,inverse_shallow_map,s,ξ))\n",
    "println(\"second method \" , estimation_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b629a",
   "metadata": {},
   "source": [
    "Therefore we will use the second method for this tutorial, and now postprocess over all measurement settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8663bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:33\u001b[39m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "\n",
    "using ProgressMeter\n",
    "observable_e = zeros(Float64,N-1);\n",
    "observable_e_square = zeros(Float64,N-1); #to assess statistical errors\n",
    "\n",
    "\n",
    "@showprogress dt=1 for r in 1:NU\n",
    "    measurement_data = measurement_group_dense.measurements[r]\n",
    "    for j in 1:N-1\n",
    "        term = real(get_expect_shadow(observable[j],measurement_data,inverse_shallow_map,s,ξ))\n",
    "        observable_e[j] += term/NU\n",
    "        observable_e_square[j] += term^2/NU\n",
    "     end\n",
    "end\n",
    "\n",
    "observable_std = sqrt.(observable_e_square .- observable_e.^2)/sqrt(NU); # standard deviation on the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bef2608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LaTeXStrings\n",
    "plot_font = \"Computer Modern\"\n",
    "default(fontfamily=plot_font,\n",
    "        linewidth=2, framestyle=:box, label=nothing, grid=false)\n",
    "scalefontsizes(1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5487c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/vermersch/Fig5.pdf\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(observable_exact,label=\"exact\")\n",
    "plot!(observable_e,yerr=observable_std,msc=2,label=\"estimated\")\n",
    "xlabel!(L\"$i$\")\n",
    "ylabel!(L\"$X_iX_{i+1}$\")\n",
    "savefig(\"~/Fig5.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "002a94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional comparison with local observable estimation\n",
    "#measurement_group_local = MeasurementGroup(ψ,NU,NM;mode=\"dense\");\n",
    "#observable_e_local = zeros(Float64,N-1);\n",
    "#observable_std_local = zeros(Float64,N-1);\n",
    "\n",
    "\n",
    "#@showprogress dt=1 for i in 1:N-1\n",
    "#    reduced_O=MPO(ComplexF64,[ξ[i],ξ[i+1]],[\"X\",\"X\"]);\n",
    "#    reduced_group = reduce_to_subsystem(measurement_group_local, collect(i:i+1))\n",
    "#    shadows = get_dense_shadows(reduced_group)\n",
    "#    observable_e_local[i], observable_std_local[i] = real.(get_expect_shadow(reduced_O,shadows,compute_sem = true));#\n",
    "#\n",
    "#end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
